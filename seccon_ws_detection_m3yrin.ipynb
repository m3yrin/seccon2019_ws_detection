{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seccon_ws_detection_m3yrin.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m3yrin/seccon2019_ws_detection/blob/master/seccon_ws_detection_m3yrin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1_5Busp3cYf",
        "colab_type": "text"
      },
      "source": [
        "# CNN model for 攻撃自動検知ワークショップ in SECCON 2019 \n",
        "\n",
        "https://connpass.com/event/159753/  \n",
        "seccon_ws_detection  \n",
        "\n",
        "auther : ＠m3yrin\n",
        "\n",
        "## Model Specification\n",
        "* Char-Base CNN sequence modeling\n",
        "\n",
        "## Memo\n",
        "* Bulit on AllenNLP\n",
        "* Tested on Google Colaboratory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za5eHvTQ4GbW",
        "colab_type": "text"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvdF94MkdMOq",
        "colab_type": "code",
        "outputId": "7db99249-2e2b-44b2-d1e3-7f9f83a0c4f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/palloc/seccon_ws_detection.git\n",
        "!pip install allennlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'seccon_ws_detection'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 19 (delta 1), reused 17 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n",
            "Collecting allennlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/bb/041115d8bad1447080e5d1e30097c95e4b66e36074277afce8620a61cee3/allennlp-0.9.0-py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.17.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.21.3)\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/a6/e69e38f1f259fcf8532d8bd2c4bc88764f42d7b35a41423a7f4b035cc5ce/jsonnet-0.14.0.tar.gz (253kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 51.8MB/s \n",
            "\u001b[?25hCollecting flaky\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/12/0f169abf1aa07c7edef4855cca53703d2e6b7ecbded7829588ac7e7e3424/flaky-3.6.1-py2.py3-none-any.whl\n",
            "Collecting flask-cors>=3.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n",
            "Collecting pytorch-pretrained-bert>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 52.5MB/s \n",
            "\u001b[?25hCollecting overrides\n",
            "  Downloading https://files.pythonhosted.org/packages/86/7a/532fc167366797f66c732549490dcf13243077f15446115f3c0ad17e56b8/overrides-2.6.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.3)\n",
            "Collecting responses>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/3e/0c/940781dd49710f4b1f0650c450c9fd8491db0e1bffd99ebc36355607f96d/responses-0.10.9-py2.py3-none-any.whl\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/5c/e918d9f190baab8d55bad52840d8091dd5114cc99f03eaa6d72d404503cc/tensorboardX-1.9-py2.py3-none-any.whl (190kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 50.7MB/s \n",
            "\u001b[?25hCollecting parsimonious>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ca/2d9a5030eaf1bcd925dab392762b9709a7ad4bd486a90599d93cd79cb188/ftfy-5.6.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n",
            "Collecting numpydoc>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f3/7cfe4c616e4b9fe05540256cc9c6661c052c8a4cec2915732793b36e1843/numpydoc-0.9.1.tar.gz\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.10.40)\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/07/07/c157520a3ebd166c8c24c6ae0ecae7c3968eb4653ff0e5af369bb82f004d/jsonpickle-1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n",
            "Requirement already satisfied: spacy<2.2,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.1.9)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.1)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Collecting conllu==1.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.1.2)\n",
            "Collecting word2number>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Collecting pytorch-transformers==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.14.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (2.10.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (0.16.0)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.6/dist-packages (from flask-cors>=3.0.7->allennlp) (1.12.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.0->allennlp) (2019.12.9)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.10.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.7)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (1.13.40)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.2.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.3)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.9.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.4.2)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (7.0.8)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.2.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.2.4)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (42.0.2)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 43.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask>=1.0.2->allennlp) (1.1.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.0.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.7.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.15.2)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (19.2)\n",
            "Building wheels for collected packages: jsonnet, overrides, parsimonious, ftfy, numpydoc, word2number\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.14.0-cp36-cp36m-linux_x86_64.whl size=3320364 sha256=c42bd55f194c36a270cc43411bcb3a545d949a1aca941efba5e13401126c1730\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/b7/83/985f0f758fbb34f14989a0fab86d18890d1cc5ae12f26967bc\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.6-cp36-none-any.whl size=5523 sha256=3733425644e9652d6070d27c382e259468b2a2dee6f959e7c616d41d2c7205f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/86/49/c413319bcff638bdc13462c063c84d68e294d84514170c3744\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42709 sha256=b2f77378c70e0f753ed13cc2abc3bf4b9fb0e38427d970e3c6323f433d721cc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.6-cp36-none-any.whl size=44553 sha256=b34bba2e2b1a076073b8403bdc20cc4339665e954e67fe293bc517702129e22e\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/ce/cbb38d71543c408de56f3c5e26ce8ba495a0fa5a28eaaf1046\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpydoc: filename=numpydoc-0.9.1-cp36-none-any.whl size=31872 sha256=8386286751df896e16069e6bd04fa00c1e324e9f399f1a5ac1204eeeee2efb04\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/30/d1/92a39ba40f21cb70e53f8af96eb98f002a781843c065406500\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5588 sha256=7890f24f4fc3d87db801ec7573b87f2d617f737a25a0d1883f1e2dbde9a84b58\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "Successfully built jsonnet overrides parsimonious ftfy numpydoc word2number\n",
            "Installing collected packages: unidecode, jsonnet, flaky, flask-cors, pytorch-pretrained-bert, overrides, responses, tensorboardX, parsimonious, ftfy, numpydoc, jsonpickle, conllu, word2number, sentencepiece, pytorch-transformers, allennlp\n",
            "Successfully installed allennlp-0.9.0 conllu-1.3.1 flaky-3.6.1 flask-cors-3.0.8 ftfy-5.6 jsonnet-0.14.0 jsonpickle-1.2 numpydoc-0.9.1 overrides-2.6 parsimonious-0.8.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 responses-0.10.9 sentencepiece-0.1.85 tensorboardX-1.9 unidecode-1.1.1 word2number-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecNA1XeQdQmz",
        "colab_type": "code",
        "outputId": "8744b89c-4513-4d89-f171-b6337adecd36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd seccon_ws_detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/seccon_ws_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK0ARpOC5akT",
        "colab_type": "code",
        "outputId": "63ce0aaa-61f9-4729-afc9-e0b79af3d899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget -P dataset https://raw.githubusercontent.com/palloc/seccon_ws_detection/score/dataset/level2_train.tsv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-23 05:20:00--  https://raw.githubusercontent.com/palloc/seccon_ws_detection/score/dataset/level2_train.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12683 (12K) [text/plain]\n",
            "Saving to: ‘dataset/level2_train.tsv’\n",
            "\n",
            "\rlevel2_train.tsv      0%[                    ]       0  --.-KB/s               \rlevel2_train.tsv    100%[===================>]  12.39K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-12-23 05:20:01 (149 MB/s) - ‘dataset/level2_train.tsv’ saved [12683/12683]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8hxm3G4vztp",
        "colab_type": "code",
        "outputId": "c5db69ce-c5c8-44e5-b3ce-4fd0c33c9b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset  score.py  simple_classifier.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3K4SJtw2rai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filepath configs\n",
        "import os\n",
        "\n",
        "full_path = './'\n",
        "DATA_DIR = os.path.join(full_path, 'dataset')\n",
        "\n",
        "#ORIGINAL_FILE = 'level1_train.tsv'\n",
        "ORIGINAL_FILE = 'level2_train.tsv'\n",
        "ORIGINAL_PATH = os.path.join(DATA_DIR, ORIGINAL_FILE)\n",
        "\n",
        "#TRAIN_FILE = 'level1_split_train.tsv'\n",
        "TRAIN_FILE = 'level2_split_train.tsv'\n",
        "TRAIN_PATH = os.path.join(DATA_DIR, TRAIN_FILE)\n",
        "\n",
        "#VALID_FILE = 'level_split_valid.tsv'\n",
        "VALID_FILE = 'level2_split_valid.tsv'\n",
        "VALID_PATH = os.path.join(DATA_DIR, VALID_FILE)\n",
        "\n",
        "AUG_FILE = 'train_aug.tsv'\n",
        "AUG_PATH = os.path.join(DATA_DIR, AUG_FILE)\n",
        "\n",
        "# for random seed.\n",
        "random_state = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CHAcvy4LlCw",
        "colab_type": "text"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKReeNBevkdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import codecs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(seed=random_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3bwZ2YjLmrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dataset.\n",
        "def load_dataset(path, num_augment = None):\n",
        "    dataset = []\n",
        "    X = []\n",
        "    y = []\n",
        "    with codecs.open(path, mode='r', encoding='utf-8') as fin:\n",
        "        dataset.extend(fin.readlines())\n",
        "    \n",
        "    for payload in dataset:\n",
        "        X.append(payload.split('\\t')[0])\n",
        "\n",
        "        label = payload.split('\\t')[1].replace('\\n', '')\n",
        "        label = int(label)\n",
        "        y.append(label)\n",
        "\n",
        "    # Data augmentation\n",
        "    # sampling random 2 indices and concatinating them.\n",
        "    if num_augment is not None:\n",
        "        X_aug = []\n",
        "        y_aug = []\n",
        "\n",
        "        ids_list = np.random.randint(len(X), size=(num_augment, 2))\n",
        "\n",
        "        for ids in ids_list:\n",
        "            X_concat = X[ids[0]] + X[ids[1]]\n",
        "\n",
        "            y_concat = 1 if y[ids[0]] + y[ids[1]] > 0 else 0\n",
        "\n",
        "            X_aug.append(X_concat)\n",
        "            y_aug.append(y_concat)\n",
        "        \n",
        "        # Also added original sequences\n",
        "        return  X_aug + X, y_aug + y\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxZXNriqLuBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = load_dataset(ORIGINAL_PATH)\n",
        "data_df = pd.DataFrame(zip(X, y))\n",
        "data_df.columns = ['X','y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm7ieqj8wy8y",
        "colab_type": "code",
        "outputId": "bdc6b75c-f8b1-484b-e7ef-893c0bfc97c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lipman@oasys.dt.navy.mil (Robert Lipman)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: CALL FOR PRESENTATIONS: Navy SciViz/V...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SPONSOR: NESS (Navy Engineering Software Syste...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This computer is occurred a error on the memory.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The purpose of the seminar is to present and e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   X  y\n",
              "0     From: lipman@oasys.dt.navy.mil (Robert Lipman)  0\n",
              "1  Subject: CALL FOR PRESENTATIONS: Navy SciViz/V...  0\n",
              "2  SPONSOR: NESS (Navy Engineering Software Syste...  0\n",
              "3   This computer is occurred a error on the memory.  0\n",
              "4  The purpose of the seminar is to present and e...  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck9UYTm-wzvJ",
        "colab_type": "code",
        "outputId": "adbd3187-380d-475d-ad4a-0bcc375725dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "data_df.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.501255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                y\n",
              "count  200.000000\n",
              "mean     0.500000\n",
              "std      0.501255\n",
              "min      0.000000\n",
              "25%      0.000000\n",
              "50%      0.500000\n",
              "75%      1.000000\n",
              "max      1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqTwbP9ZxjhA",
        "colab_type": "code",
        "outputId": "df949b89-45c5-48b8-ec5a-6a24425d365e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "# check the distribution of y\n",
        "data_df.y.value_counts().plot(kind=\"bar\")\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD1CAYAAACrz7WZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd0lqyLhLUkPGXZIa+h9/5BcFpHm8eAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VvlmfHDM7hx",
        "colab_type": "text"
      },
      "source": [
        "## File Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTCgz8vhQ6oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_size = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui3nzWJSwM11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmXyFU2KNSEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=test_size, random_state=random_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urwIE_ZDNg4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.DataFrame(zip(train_X, train_y))\n",
        "valid_df = pd.DataFrame(zip(valid_X, valid_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i21L9xvN7Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.to_csv(TRAIN_PATH, sep='\\t', index=False, header=False)\n",
        "valid_df.to_csv(VALID_PATH, sep='\\t', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifvlluJmyR-8",
        "colab_type": "text"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cekbz95Q3oY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_augment = 400"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvAQdvmPwf-q",
        "colab_type": "code",
        "outputId": "7a0a4ad6-7d27-49af-faa6-08875c206941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X, y = load_dataset(TRAIN_PATH, num_augment = num_augment)\n",
        "\n",
        "data_auged_df = pd.DataFrame(zip(X, y))\n",
        "data_auged_df.columns = ['X','y']\n",
        "data_auged_df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Added lines are prepended with a `+'The frame ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"\"\"&lt;/table&gt;&lt;video&gt;&lt;source onerror=jAvaScrIpt:w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;svg/onload=alert(1); &lt;/del&gt;&amp;#x09;rel=&lt;video&gt;&lt;...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>good service, too. But if you think all local ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>javascript:\\u0061lert();&lt;/script&gt;&lt;frameset&gt;&lt;ba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   X  y\n",
              "0  Added lines are prepended with a `+'The frame ...  0\n",
              "1  \"\"\"</table><video><source onerror=jAvaScrIpt:w...  1\n",
              "2  <svg/onload=alert(1); </del>&#x09;rel=<video><...  1\n",
              "3  good service, too. But if you think all local ...  1\n",
              "4  javascript:\\u0061lert();</script><frameset><ba...  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie7BlA_TwmS0",
        "colab_type": "code",
        "outputId": "fab0516d-3b4f-47cd-cfc5-f9b30b4bac17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "data_auged_df.describe()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>560.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.685714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.464646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                y\n",
              "count  560.000000\n",
              "mean     0.685714\n",
              "std      0.464646\n",
              "min      0.000000\n",
              "25%      0.000000\n",
              "50%      1.000000\n",
              "75%      1.000000\n",
              "max      1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAv90JnDMBYj",
        "colab_type": "code",
        "outputId": "bb4b18ae-297c-4597-dd06-c4977aec06dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "data_auged_df.y.value_counts().plot(kind=\"bar\")\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD3CAYAAADmBxSSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6pDhLkkd+j+JhPH3ua093wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5mWEnxSMXNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_auged_df.to_csv(AUG_PATH, sep='\\t' , index = False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDKtqZjxMXKI",
        "colab_type": "code",
        "outputId": "849b5923-6d6d-48d9-e24c-2d5971f0d336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls dataset"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "level1_test.tsv   level2_split_train.tsv  level2_train.tsv\n",
            "level1_train.tsv  level2_split_valid.tsv  train_aug.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoJTHRSIL_3h",
        "colab_type": "text"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdX1kOe5RV3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "\n",
        "## for model\n",
        "char_min_count = 1\n",
        "batch_size = 32\n",
        "hidden_dim = 64\n",
        "dropout_prob = 0.2\n",
        "\n",
        "## for training\n",
        "LR = 1e-4\n",
        "PATIENCE = 50\n",
        "EPOCHS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7MZ71Vn2LdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import codecs\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "import itertools\n",
        "import json\n",
        "import logging\n",
        "import string\n",
        "from collections import defaultdict\n",
        "from typing import Dict, List, Union, Tuple, Any, Optional\n",
        "\n",
        "from overrides import overrides\n",
        "from word2number.w2n import word_to_num\n",
        "\n",
        "import torch\n",
        "\n",
        "import allennlp\n",
        "from allennlp.common.file_utils import cached_path\n",
        "from allennlp.data.fields import (\n",
        "    Field,\n",
        "    TextField,\n",
        "    MetadataField,\n",
        "    LabelField,\n",
        "    ListField,\n",
        "    SequenceLabelField,\n",
        "    SpanField,\n",
        "    IndexField,\n",
        ")\n",
        "\n",
        "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
        "from allennlp.data.instance import Instance\n",
        "from allennlp.data.tokenizers import Token, Tokenizer\n",
        "from allennlp.data.token_indexers.token_indexer import TokenIndexer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn4zlw2E2LaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# logging setting\n",
        "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-t7DIUA3Tdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lv1Reader(DatasetReader):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer: Tokenizer = None,\n",
        "        token_indexers: Dict[str, TokenIndexer] = None,\n",
        "        lazy: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__(lazy)\n",
        "        self._tokenizer = tokenizer or WhitespaceTokenizer()\n",
        "        self._token_indexers = token_indexers\n",
        "\n",
        "    @overrides\n",
        "    def _read(self, file_path: str):\n",
        "        file_path = cached_path(file_path)\n",
        "        \n",
        "        with codecs.open(file_path, mode='r', encoding='utf-8') as dataset_file:\n",
        "            for line in dataset_file:\n",
        "                \n",
        "                example = line.split('\\t')\n",
        "                payload = example[0]\n",
        "                payload = self._tokenizer.tokenize(payload)\n",
        "\n",
        "                target = None\n",
        "                if len(example) == 2:\n",
        "                    target = example[1].replace('\\n', '')\n",
        "                    target = int(target)\n",
        "                \n",
        "                instance = self.text_to_instance(\n",
        "                    payload,\n",
        "                    target,\n",
        "                )\n",
        "                yield instance\n",
        "                \n",
        "\n",
        "    @overrides\n",
        "    def text_to_instance(\n",
        "        self,  # type: ignore\n",
        "        payload: str,\n",
        "        target: int,\n",
        "        ) -> Union[Instance, None]:\n",
        "        \n",
        "        fields: Dict[str, Field] = {}\n",
        "        fields[\"payload\"] = TextField(payload, self._token_indexers)\n",
        "\n",
        "        if target is not None:\n",
        "            fields[\"target\"] = LabelField(target, skip_indexing=True)\n",
        "        \n",
        "        return Instance(fields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7gAlraO3TVZ",
        "colab_type": "code",
        "outputId": "77c3447d-cc9b-44b7-8949-2b4214566058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from allennlp.data.tokenizers.character_tokenizer import CharacterTokenizer\n",
        "from allennlp.data.token_indexers.token_characters_indexer import TokenCharactersIndexer\n",
        "from allennlp.data.token_indexers.single_id_token_indexer import SingleIdTokenIndexer\n",
        "\n",
        "\n",
        "reader = Lv1Reader(tokenizer = CharacterTokenizer(),\n",
        "                   token_indexers = {\"tokens\": SingleIdTokenIndexer(lowercase_tokens = True)}\n",
        "                  )\n",
        "\n",
        "train_dataset = reader.read(AUG_PATH)\n",
        "valid_dataset = reader.read(VALID_PATH)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "560it [00:00, 3307.65it/s]\n",
            "40it [00:00, 5033.52it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNB7WaRQ2HdE",
        "colab_type": "code",
        "outputId": "7e965f02-9475-403e-fb1c-e890d5b148c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from allennlp.data.vocabulary import Vocabulary\n",
        "vocab = Vocabulary.from_instances(train_dataset, min_count={'tokens': char_min_count})\n",
        "vocab"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting token dictionary from dataset.\n",
            "100%|██████████| 560/560 [00:00<00:00, 10789.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Vocabulary with namespaces:  tokens, Size: 70 || Non Padded Namespaces: {'*labels', '*tags'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5x-zVXn_mN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import BasicIterator, BucketIterator\n",
        "\n",
        "iterator = BucketIterator(\n",
        "    batch_size=batch_size,\n",
        "    sorting_keys=[(\"payload\", \"num_tokens\")],\n",
        ")\n",
        "iterator.index_with(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Guo3R8nNzk_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.modules.token_embedders import Embedding\n",
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "\n",
        "embedding = Embedding(num_embeddings=vocab.get_vocab_size(), embedding_dim=hidden_dim, padding_index=0)\n",
        "embedder = BasicTextFieldEmbedder({\"tokens\": embedding})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asYKv35WFAOK",
        "colab_type": "code",
        "outputId": "81271141-0e8b-43b8-80a9-d1a7faa4c075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from allennlp.nn.util import get_text_field_mask\n",
        "\n",
        "from allennlp.models.model import Model\n",
        "from allennlp.modules import FeedForward, Seq2SeqEncoder, Seq2VecEncoder, TextFieldEmbedder\n",
        "from allennlp.nn import InitializerApplicator, RegularizerApplicator\n",
        "from allennlp.training.metrics import CategoricalAccuracy\n",
        "from allennlp.training.metrics.auc import Auc\n",
        "\n",
        "class Lv1Net(Model):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab: Vocabulary,\n",
        "        text_field_embedder: TextFieldEmbedder,\n",
        "        seq2vec_encoder: Seq2VecEncoder,\n",
        "        num_labels: int,\n",
        "        feedforward: Optional[FeedForward] = None,\n",
        "        dropout_prob: float = 0.1,\n",
        "        initializer: InitializerApplicator = InitializerApplicator(),\n",
        "        regularizer: Optional[RegularizerApplicator] = None,\n",
        "    ) -> None:\n",
        "        super().__init__(vocab, regularizer)\n",
        "\n",
        "        self._text_field_embedder = text_field_embedder\n",
        "        text_embed_dim = text_field_embedder.get_output_dim()\n",
        "        self._dropout = torch.nn.Dropout(p=dropout_prob)\n",
        "\n",
        "        self._seq2vec_encoder = seq2vec_encoder\n",
        "        self._feedforward = feedforward\n",
        "        self._num_labels = num_labels\n",
        "        \n",
        "        if feedforward is not None:\n",
        "            self._classifier_input_dim = self._feedforward.get_output_dim()\n",
        "        else:\n",
        "            self._classifier_input_dim = self._seq2vec_encoder.get_output_dim()\n",
        "\n",
        "        self._classification_layer = torch.nn.Linear(self._classifier_input_dim, self._num_labels)\n",
        "\n",
        "        self._accuracy = CategoricalAccuracy()\n",
        "        self._auc = Auc(positive_label = 1)\n",
        "        self._loss = torch.nn.CrossEntropyLoss()\n",
        "        initializer(self)\n",
        "        \n",
        "\n",
        "    def forward(  # type: ignore\n",
        "        self,\n",
        "        payload: Dict[str, torch.LongTensor],\n",
        "        target: torch.IntTensor = None,\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "\n",
        "        \n",
        "        mask = get_text_field_mask(payload).float()\n",
        "\n",
        "\n",
        "        # Shape: (batch_size, payload_length, hidden)\n",
        "        embedded_text = self._text_field_embedder(payload)\n",
        "        embedded_text = self._seq2vec_encoder(embedded_text, mask=mask)\n",
        "\n",
        "        embedded_text = self._dropout(embedded_text)\n",
        "\n",
        "        if self._feedforward is not None:\n",
        "            embedded_text = self._feedforward(embedded_text)\n",
        "\n",
        "        logits = self._classification_layer(embedded_text)\n",
        "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "        output_dict = {\"logits\": logits, \"probs\": probs}\n",
        "\n",
        "        if target is not None:\n",
        "            loss = self._loss(logits, target.long().view(-1))\n",
        "            output_dict[\"loss\"] = loss\n",
        "            self._accuracy(logits, target)\n",
        "            self._auc(logits.argmax(dim=1), target)\n",
        "        \n",
        "        return output_dict\n",
        "\n",
        "    @overrides\n",
        "    def decode(self, output_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Does a simple argmax over the probabilities, converts index to string label, and\n",
        "        add ``\"label\"`` key to the dictionary with the result.\n",
        "        \"\"\"\n",
        "        predictions = output_dict[\"probs\"]\n",
        "        if predictions.dim() == 2:\n",
        "            predictions_list = [predictions[i] for i in range(predictions.shape[0])]\n",
        "        else:\n",
        "            predictions_list = [predictions]\n",
        "        classes = []\n",
        "        for prediction in predictions_list:\n",
        "            label_idx = prediction.argmax(dim=-1).item()\n",
        "            label_str = str(label_idx)\n",
        "            classes.append(label_str)\n",
        "        output_dict[\"label\"] = classes\n",
        "        return output_dict\n",
        "\n",
        "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
        "        metrics = {\"accuracy\": self._accuracy.get_metric(reset), \"auc\": self._auc.get_metric(reset)}\n",
        "        return metrics"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WvuD2-5Kzgl",
        "colab_type": "code",
        "outputId": "2fab2ae5-3bfa-43f7-caff-ffaea424d148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from allennlp.modules.seq2vec_encoders.cnn_encoder import CnnEncoder\n",
        "encoder = CnnEncoder(embedding_dim = hidden_dim, num_filters = hidden_dim)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-cNlfJtKzeG",
        "colab_type": "code",
        "outputId": "9c9c3ec7-6041-460a-bf9c-371daa6ced55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model = Lv1Net(vocab = vocab,\n",
        "               text_field_embedder = embedder,\n",
        "               seq2vec_encoder = encoder,\n",
        "               num_labels = 2,\n",
        "               dropout_prob = dropout_prob\n",
        "               )"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing parameters\n",
            "Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "   _classification_layer.bias\n",
            "   _classification_layer.weight\n",
            "   _seq2vec_encoder.conv_layer_0.bias\n",
            "   _seq2vec_encoder.conv_layer_0.weight\n",
            "   _seq2vec_encoder.conv_layer_1.bias\n",
            "   _seq2vec_encoder.conv_layer_1.weight\n",
            "   _seq2vec_encoder.conv_layer_2.bias\n",
            "   _seq2vec_encoder.conv_layer_2.weight\n",
            "   _seq2vec_encoder.conv_layer_3.bias\n",
            "   _seq2vec_encoder.conv_layer_3.weight\n",
            "   _text_field_embedder.token_embedder_tokens.weight\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDJcbWxGKzbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoBK_BBvKzY3",
        "colab_type": "code",
        "outputId": "a7e56fb5-08c8-4d3c-e769-648852387ddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"cuda\")\n",
        "    cuda_device = 0\n",
        "    model = model.cuda(cuda_device)\n",
        "else:\n",
        "    print(\"cpu\")\n",
        "    cuda_device = -1"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_KEhpW_KzWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.training.trainer import Trainer\n",
        "\n",
        "trainer = Trainer(model = model,\n",
        "                  optimizer = optimizer,\n",
        "                  iterator = iterator,\n",
        "                  train_dataset = train_dataset,\n",
        "                  validation_dataset = valid_dataset,\n",
        "                  patience = PATIENCE,\n",
        "                  validation_metric = \"+auc\",\n",
        "                  #validation_metric = \"+accuracy\",\n",
        "                  num_epochs = EPOCHS,\n",
        "                  cuda_device = cuda_device\n",
        "                 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZe7GAL-KzS8",
        "colab_type": "code",
        "outputId": "254d7559-9b8d-49b0-b3c5-47604ecb3aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning training.\n",
            "Epoch 0/99\n",
            "Peak CPU memory usage MB: 2600.688\n",
            "GPU 0 memory usage MB: 719\n",
            "Training\n",
            "accuracy: 0.4000, auc: 0.5086, loss: 0.7155 ||: 100%|██████████| 18/18 [00:00<00:00, 23.68it/s]\n",
            "Validating\n",
            "accuracy: 0.6750, auc: 0.6439, loss: 0.6816 ||: 100%|██████████| 2/2 [00:00<00:00, 130.04it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   719.000  |       N/A\n",
            "cpu_memory_MB   |  2600.688  |       N/A\n",
            "loss            |     0.715  |     0.682\n",
            "auc             |     0.509  |     0.644\n",
            "accuracy        |     0.400  |     0.675\n",
            "Epoch duration: 0:00:00.864592\n",
            "Estimated training time remaining: 0:01:25\n",
            "Epoch 1/99\n",
            "Peak CPU memory usage MB: 2617.28\n",
            "GPU 0 memory usage MB: 773\n",
            "Training\n",
            "accuracy: 0.6696, auc: 0.5083, loss: 0.6596 ||: 100%|██████████| 18/18 [00:00<00:00, 64.37it/s]\n",
            "Validating\n",
            "accuracy: 0.5500, auc: 0.5000, loss: 0.6706 ||: 100%|██████████| 2/2 [00:00<00:00, 228.70it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   773.000  |       N/A\n",
            "cpu_memory_MB   |  2617.280  |       N/A\n",
            "loss            |     0.660  |     0.671\n",
            "auc             |     0.508  |     0.500\n",
            "accuracy        |     0.670  |     0.550\n",
            "Epoch duration: 0:00:00.393391\n",
            "Estimated training time remaining: 0:01:01\n",
            "Epoch 2/99\n",
            "Peak CPU memory usage MB: 2617.344\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.6857, auc: 0.5000, loss: 0.6139 ||: 100%|██████████| 18/18 [00:00<00:00, 64.41it/s]\n",
            "Validating\n",
            "accuracy: 0.5500, auc: 0.5000, loss: 0.6585 ||: 100%|██████████| 2/2 [00:00<00:00, 214.81it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2617.344  |       N/A\n",
            "loss            |     0.614  |     0.658\n",
            "auc             |     0.500  |     0.500\n",
            "accuracy        |     0.686  |     0.550\n",
            "Epoch duration: 0:00:00.392822\n",
            "Estimated training time remaining: 0:00:53\n",
            "Epoch 3/99\n",
            "Peak CPU memory usage MB: 2617.368\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.6857, auc: 0.5000, loss: 0.5915 ||: 100%|██████████| 18/18 [00:00<00:00, 62.67it/s]\n",
            "Validating\n",
            "accuracy: 0.5500, auc: 0.5000, loss: 0.6294 ||: 100%|██████████| 2/2 [00:00<00:00, 168.27it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2617.368  |       N/A\n",
            "loss            |     0.592  |     0.629\n",
            "auc             |     0.500  |     0.500\n",
            "accuracy        |     0.686  |     0.550\n",
            "Epoch duration: 0:00:00.401590\n",
            "Estimated training time remaining: 0:00:49\n",
            "Epoch 4/99\n",
            "Peak CPU memory usage MB: 2617.376\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.6857, auc: 0.5000, loss: 0.5653 ||: 100%|██████████| 18/18 [00:00<00:00, 65.42it/s]\n",
            "Validating\n",
            "accuracy: 0.5500, auc: 0.5000, loss: 0.6427 ||: 100%|██████████| 2/2 [00:00<00:00, 186.79it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2617.376  |       N/A\n",
            "loss            |     0.565  |     0.643\n",
            "auc             |     0.500  |     0.500\n",
            "accuracy        |     0.686  |     0.550\n",
            "Epoch duration: 0:00:00.387404\n",
            "Estimated training time remaining: 0:00:46\n",
            "Epoch 5/99\n",
            "Peak CPU memory usage MB: 2617.512\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.6857, auc: 0.5000, loss: 0.5487 ||: 100%|██████████| 18/18 [00:00<00:00, 64.95it/s]\n",
            "Validating\n",
            "accuracy: 0.5500, auc: 0.5000, loss: 0.6366 ||: 100%|██████████| 2/2 [00:00<00:00, 168.83it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2617.512  |       N/A\n",
            "loss            |     0.549  |     0.637\n",
            "auc             |     0.500  |     0.500\n",
            "accuracy        |     0.686  |     0.550\n",
            "Epoch duration: 0:00:00.385348\n",
            "Estimated training time remaining: 0:00:44\n",
            "Epoch 6/99\n",
            "Peak CPU memory usage MB: 2618.052\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.6857, auc: 0.5000, loss: 0.5335 ||: 100%|██████████| 18/18 [00:00<00:00, 64.74it/s]\n",
            "Validating\n",
            "accuracy: 0.5500, auc: 0.5000, loss: 0.6257 ||: 100%|██████████| 2/2 [00:00<00:00, 199.14it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2618.052  |       N/A\n",
            "loss            |     0.533  |     0.626\n",
            "auc             |     0.500  |     0.500\n",
            "accuracy        |     0.686  |     0.550\n",
            "Epoch duration: 0:00:00.390964\n",
            "Estimated training time remaining: 0:00:43\n",
            "Epoch 7/99\n",
            "Peak CPU memory usage MB: 2618.252\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.6857, auc: 0.5000, loss: 0.5183 ||: 100%|██████████| 18/18 [00:00<00:00, 64.75it/s]\n",
            "Validating\n",
            "accuracy: 0.5500, auc: 0.5000, loss: 0.5785 ||: 100%|██████████| 2/2 [00:00<00:00, 171.59it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2618.252  |       N/A\n",
            "loss            |     0.518  |     0.578\n",
            "auc             |     0.500  |     0.500\n",
            "accuracy        |     0.686  |     0.550\n",
            "Epoch duration: 0:00:00.392823\n",
            "Estimated training time remaining: 0:00:41\n",
            "Epoch 8/99\n",
            "Peak CPU memory usage MB: 2618.4\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.6857, auc: 0.5000, loss: 0.5003 ||: 100%|██████████| 18/18 [00:00<00:00, 64.39it/s]\n",
            "Validating\n",
            "accuracy: 0.5500, auc: 0.5000, loss: 0.5921 ||: 100%|██████████| 2/2 [00:00<00:00, 125.25it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2618.400  |       N/A\n",
            "loss            |     0.500  |     0.592\n",
            "auc             |     0.500  |     0.500\n",
            "accuracy        |     0.686  |     0.550\n",
            "Epoch duration: 0:00:00.395403\n",
            "Estimated training time remaining: 0:00:40\n",
            "Epoch 9/99\n",
            "Peak CPU memory usage MB: 2618.544\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.6857, auc: 0.5000, loss: 0.4804 ||: 100%|██████████| 18/18 [00:00<00:00, 67.76it/s]\n",
            "Validating\n",
            "accuracy: 0.5500, auc: 0.5000, loss: 0.5381 ||: 100%|██████████| 2/2 [00:00<00:00, 150.90it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2618.544  |       N/A\n",
            "loss            |     0.480  |     0.538\n",
            "auc             |     0.500  |     0.500\n",
            "accuracy        |     0.686  |     0.550\n",
            "Epoch duration: 0:00:00.369983\n",
            "Estimated training time remaining: 0:00:39\n",
            "Epoch 10/99\n",
            "Peak CPU memory usage MB: 2618.664\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.6857, auc: 0.5000, loss: 0.4681 ||: 100%|██████████| 18/18 [00:00<00:00, 65.53it/s]\n",
            "Validating\n",
            "accuracy: 0.5500, auc: 0.5000, loss: 0.5529 ||: 100%|██████████| 2/2 [00:00<00:00, 154.02it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2618.664  |       N/A\n",
            "loss            |     0.468  |     0.553\n",
            "auc             |     0.500  |     0.500\n",
            "accuracy        |     0.686  |     0.550\n",
            "Epoch duration: 0:00:00.377923\n",
            "Estimated training time remaining: 0:00:38\n",
            "Epoch 11/99\n",
            "Peak CPU memory usage MB: 2618.988\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "  0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:651: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n",
            "accuracy: 0.6857, auc: 0.5000, loss: 0.4457 ||: 100%|██████████| 18/18 [00:00<00:00, 61.48it/s]\n",
            "Validating\n",
            "accuracy: 0.5500, auc: 0.5000, loss: 0.5296 ||: 100%|██████████| 2/2 [00:00<00:00, 149.25it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2618.988  |       N/A\n",
            "loss            |     0.446  |     0.530\n",
            "auc             |     0.500  |     0.500\n",
            "accuracy        |     0.686  |     0.550\n",
            "Epoch duration: 0:00:00.400762\n",
            "Estimated training time remaining: 0:00:38\n",
            "Epoch 12/99\n",
            "Peak CPU memory usage MB: 2619.052\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.6946, auc: 0.5142, loss: 0.4264 ||: 100%|██████████| 18/18 [00:00<00:00, 64.69it/s]\n",
            "Validating\n",
            "accuracy: 0.5500, auc: 0.5000, loss: 0.4773 ||: 100%|██████████| 2/2 [00:00<00:00, 152.26it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.052  |       N/A\n",
            "loss            |     0.426  |     0.477\n",
            "auc             |     0.514  |     0.500\n",
            "accuracy        |     0.695  |     0.550\n",
            "Epoch duration: 0:00:00.384808\n",
            "Estimated training time remaining: 0:00:37\n",
            "Epoch 13/99\n",
            "Peak CPU memory usage MB: 2619.104\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.7161, auc: 0.5483, loss: 0.4118 ||: 100%|██████████| 18/18 [00:00<00:00, 65.13it/s]\n",
            "Validating\n",
            "accuracy: 0.6000, auc: 0.5556, loss: 0.4728 ||: 100%|██████████| 2/2 [00:00<00:00, 146.60it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.104  |       N/A\n",
            "loss            |     0.412  |     0.473\n",
            "auc             |     0.548  |     0.556\n",
            "accuracy        |     0.716  |     0.600\n",
            "Epoch duration: 0:00:00.384886\n",
            "Estimated training time remaining: 0:00:36\n",
            "Epoch 14/99\n",
            "Peak CPU memory usage MB: 2619.104\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.7661, auc: 0.6278, loss: 0.3935 ||: 100%|██████████| 18/18 [00:00<00:00, 64.82it/s]\n",
            "Validating\n",
            "accuracy: 0.6750, auc: 0.6389, loss: 0.4500 ||: 100%|██████████| 2/2 [00:00<00:00, 142.86it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.104  |       N/A\n",
            "loss            |     0.393  |     0.450\n",
            "auc             |     0.628  |     0.639\n",
            "accuracy        |     0.766  |     0.675\n",
            "Epoch duration: 0:00:00.391044\n",
            "Estimated training time remaining: 0:00:36\n",
            "Epoch 15/99\n",
            "Peak CPU memory usage MB: 2619.108\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.8429, auc: 0.7500, loss: 0.3680 ||: 100%|██████████| 18/18 [00:00<00:00, 66.39it/s]\n",
            "Validating\n",
            "accuracy: 0.7750, auc: 0.7500, loss: 0.4179 ||: 100%|██████████| 2/2 [00:00<00:00, 155.60it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.108  |       N/A\n",
            "loss            |     0.368  |     0.418\n",
            "auc             |     0.750  |     0.750\n",
            "accuracy        |     0.843  |     0.775\n",
            "Epoch duration: 0:00:00.382690\n",
            "Estimated training time remaining: 0:00:35\n",
            "Epoch 16/99\n",
            "Peak CPU memory usage MB: 2619.124\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.8964, auc: 0.8352, loss: 0.3465 ||: 100%|██████████| 18/18 [00:00<00:00, 64.66it/s]\n",
            "Validating\n",
            "accuracy: 0.8250, auc: 0.8056, loss: 0.3900 ||: 100%|██████████| 2/2 [00:00<00:00, 161.93it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.124  |       N/A\n",
            "loss            |     0.346  |     0.390\n",
            "auc             |     0.835  |     0.806\n",
            "accuracy        |     0.896  |     0.825\n",
            "Epoch duration: 0:00:00.380943\n",
            "Estimated training time remaining: 0:00:34\n",
            "Epoch 17/99\n",
            "Peak CPU memory usage MB: 2619.124\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9161, auc: 0.8665, loss: 0.3249 ||: 100%|██████████| 18/18 [00:00<00:00, 66.42it/s]\n",
            "Validating\n",
            "accuracy: 0.9500, auc: 0.9444, loss: 0.3662 ||: 100%|██████████| 2/2 [00:00<00:00, 189.55it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.124  |       N/A\n",
            "loss            |     0.325  |     0.366\n",
            "auc             |     0.866  |     0.944\n",
            "accuracy        |     0.916  |     0.950\n",
            "Epoch duration: 0:00:00.372567\n",
            "Estimated training time remaining: 0:00:34\n",
            "Epoch 18/99\n",
            "Peak CPU memory usage MB: 2619.124\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9321, auc: 0.8920, loss: 0.3084 ||: 100%|██████████| 18/18 [00:00<00:00, 65.68it/s]\n",
            "Validating\n",
            "accuracy: 0.9750, auc: 0.9722, loss: 0.3399 ||: 100%|██████████| 2/2 [00:00<00:00, 157.35it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.124  |       N/A\n",
            "loss            |     0.308  |     0.340\n",
            "auc             |     0.892  |     0.972\n",
            "accuracy        |     0.932  |     0.975\n",
            "Epoch duration: 0:00:00.377496\n",
            "Estimated training time remaining: 0:00:33\n",
            "Epoch 19/99\n",
            "Peak CPU memory usage MB: 2619.124\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9464, auc: 0.9148, loss: 0.2832 ||: 100%|██████████| 18/18 [00:00<00:00, 44.50it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.3157 ||: 100%|██████████| 2/2 [00:00<00:00, 142.61it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.124  |       N/A\n",
            "loss            |     0.283  |     0.316\n",
            "auc             |     0.915  |     1.000\n",
            "accuracy        |     0.946  |     1.000\n",
            "Epoch duration: 0:00:00.511373\n",
            "Estimated training time remaining: 0:00:33\n",
            "Epoch 20/99\n",
            "Peak CPU memory usage MB: 2619.124\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9554, auc: 0.9290, loss: 0.2662 ||: 100%|██████████| 18/18 [00:00<00:00, 66.03it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.2855 ||: 100%|██████████| 2/2 [00:00<00:00, 153.42it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.124  |       N/A\n",
            "loss            |     0.266  |     0.286\n",
            "auc             |     0.929  |     1.000\n",
            "accuracy        |     0.955  |     1.000\n",
            "Epoch duration: 0:00:00.373927\n",
            "Estimated training time remaining: 0:00:33\n",
            "Epoch 21/99\n",
            "Peak CPU memory usage MB: 2619.124\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9714, auc: 0.9545, loss: 0.2501 ||: 100%|██████████| 18/18 [00:00<00:00, 63.18it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.2626 ||: 100%|██████████| 2/2 [00:00<00:00, 174.47it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.124  |       N/A\n",
            "loss            |     0.250  |     0.263\n",
            "auc             |     0.955  |     1.000\n",
            "accuracy        |     0.971  |     1.000\n",
            "Epoch duration: 0:00:00.394306\n",
            "Estimated training time remaining: 0:00:32\n",
            "Epoch 22/99\n",
            "Peak CPU memory usage MB: 2619.132\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9732, auc: 0.9574, loss: 0.2307 ||: 100%|██████████| 18/18 [00:00<00:00, 66.39it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.2427 ||: 100%|██████████| 2/2 [00:00<00:00, 168.94it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.132  |       N/A\n",
            "loss            |     0.231  |     0.243\n",
            "auc             |     0.957  |     1.000\n",
            "accuracy        |     0.973  |     1.000\n",
            "Epoch duration: 0:00:00.371933\n",
            "Estimated training time remaining: 0:00:31\n",
            "Epoch 23/99\n",
            "Peak CPU memory usage MB: 2619.132\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9857, auc: 0.9773, loss: 0.2115 ||: 100%|██████████| 18/18 [00:00<00:00, 65.72it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.2185 ||: 100%|██████████| 2/2 [00:00<00:00, 142.35it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.132  |       N/A\n",
            "loss            |     0.211  |     0.218\n",
            "auc             |     0.977  |     1.000\n",
            "accuracy        |     0.986  |     1.000\n",
            "Epoch duration: 0:00:00.383445\n",
            "Estimated training time remaining: 0:00:31\n",
            "Epoch 24/99\n",
            "Peak CPU memory usage MB: 2619.148\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9839, auc: 0.9744, loss: 0.1960 ||: 100%|██████████| 18/18 [00:00<00:00, 65.58it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.2036 ||: 100%|██████████| 2/2 [00:00<00:00, 164.60it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.148  |       N/A\n",
            "loss            |     0.196  |     0.204\n",
            "auc             |     0.974  |     1.000\n",
            "accuracy        |     0.984  |     1.000\n",
            "Epoch duration: 0:00:00.381946\n",
            "Estimated training time remaining: 0:00:30\n",
            "Epoch 25/99\n",
            "Peak CPU memory usage MB: 2619.148\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9893, auc: 0.9830, loss: 0.1825 ||: 100%|██████████| 18/18 [00:00<00:00, 65.58it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.1741 ||: 100%|██████████| 2/2 [00:00<00:00, 212.78it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.148  |       N/A\n",
            "loss            |     0.183  |     0.174\n",
            "auc             |     0.983  |     1.000\n",
            "accuracy        |     0.989  |     1.000\n",
            "Epoch duration: 0:00:00.382474\n",
            "Estimated training time remaining: 0:00:30\n",
            "Epoch 26/99\n",
            "Peak CPU memory usage MB: 2619.148\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9964, auc: 0.9943, loss: 0.1668 ||: 100%|██████████| 18/18 [00:00<00:00, 66.59it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.1794 ||: 100%|██████████| 2/2 [00:00<00:00, 178.97it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.148  |       N/A\n",
            "loss            |     0.167  |     0.179\n",
            "auc             |     0.994  |     1.000\n",
            "accuracy        |     0.996  |     1.000\n",
            "Epoch duration: 0:00:00.393541\n",
            "Estimated training time remaining: 0:00:30\n",
            "Epoch 27/99\n",
            "Peak CPU memory usage MB: 2619.156\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9964, auc: 0.9943, loss: 0.1483 ||: 100%|██████████| 18/18 [00:00<00:00, 65.69it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.1490 ||: 100%|██████████| 2/2 [00:00<00:00, 162.90it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.156  |       N/A\n",
            "loss            |     0.148  |     0.149\n",
            "auc             |     0.994  |     1.000\n",
            "accuracy        |     0.996  |     1.000\n",
            "Epoch duration: 0:00:00.384752\n",
            "Estimated training time remaining: 0:00:29\n",
            "Epoch 28/99\n",
            "Peak CPU memory usage MB: 2619.156\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9929, auc: 0.9886, loss: 0.1426 ||: 100%|██████████| 18/18 [00:00<00:00, 65.20it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.1380 ||: 100%|██████████| 2/2 [00:00<00:00, 161.54it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.156  |       N/A\n",
            "loss            |     0.143  |     0.138\n",
            "auc             |     0.989  |     1.000\n",
            "accuracy        |     0.993  |     1.000\n",
            "Epoch duration: 0:00:00.399828\n",
            "Estimated training time remaining: 0:00:29\n",
            "Epoch 29/99\n",
            "Peak CPU memory usage MB: 2619.164\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9964, auc: 0.9943, loss: 0.1323 ||: 100%|██████████| 18/18 [00:00<00:00, 63.53it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.1361 ||: 100%|██████████| 2/2 [00:00<00:00, 155.78it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.164  |       N/A\n",
            "loss            |     0.132  |     0.136\n",
            "auc             |     0.994  |     1.000\n",
            "accuracy        |     0.996  |     1.000\n",
            "Epoch duration: 0:00:00.382253\n",
            "Estimated training time remaining: 0:00:28\n",
            "Epoch 30/99\n",
            "Peak CPU memory usage MB: 2619.164\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.1217 ||: 100%|██████████| 18/18 [00:00<00:00, 63.80it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.1194 ||: 100%|██████████| 2/2 [00:00<00:00, 160.82it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.164  |       N/A\n",
            "loss            |     0.122  |     0.119\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.390388\n",
            "Estimated training time remaining: 0:00:28\n",
            "Epoch 31/99\n",
            "Peak CPU memory usage MB: 2619.164\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9964, auc: 0.9943, loss: 0.1128 ||: 100%|██████████| 18/18 [00:00<00:00, 66.92it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.1188 ||: 100%|██████████| 2/2 [00:00<00:00, 135.75it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.164  |       N/A\n",
            "loss            |     0.113  |     0.119\n",
            "auc             |     0.994  |     1.000\n",
            "accuracy        |     0.996  |     1.000\n",
            "Epoch duration: 0:00:00.372967\n",
            "Estimated training time remaining: 0:00:27\n",
            "Epoch 32/99\n",
            "Peak CPU memory usage MB: 2619.164\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.1065 ||: 100%|██████████| 18/18 [00:00<00:00, 65.81it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.1017 ||: 100%|██████████| 2/2 [00:00<00:00, 155.95it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.164  |       N/A\n",
            "loss            |     0.107  |     0.102\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.391639\n",
            "Estimated training time remaining: 0:00:27\n",
            "Epoch 33/99\n",
            "Peak CPU memory usage MB: 2619.164\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0960 ||: 100%|██████████| 18/18 [00:00<00:00, 66.73it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.1008 ||: 100%|██████████| 2/2 [00:00<00:00, 150.97it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.164  |       N/A\n",
            "loss            |     0.096  |     0.101\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.378987\n",
            "Estimated training time remaining: 0:00:26\n",
            "Epoch 34/99\n",
            "Peak CPU memory usage MB: 2619.164\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0887 ||: 100%|██████████| 18/18 [00:00<00:00, 67.54it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0934 ||: 100%|██████████| 2/2 [00:00<00:00, 145.09it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.164  |       N/A\n",
            "loss            |     0.089  |     0.093\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.368958\n",
            "Estimated training time remaining: 0:00:26\n",
            "Epoch 35/99\n",
            "Peak CPU memory usage MB: 2619.164\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0830 ||: 100%|██████████| 18/18 [00:00<00:00, 64.81it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0843 ||: 100%|██████████| 2/2 [00:00<00:00, 149.23it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.164  |       N/A\n",
            "loss            |     0.083  |     0.084\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.387955\n",
            "Estimated training time remaining: 0:00:25\n",
            "Epoch 36/99\n",
            "Peak CPU memory usage MB: 2619.164\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0769 ||: 100%|██████████| 18/18 [00:00<00:00, 66.66it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0820 ||: 100%|██████████| 2/2 [00:00<00:00, 150.73it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.164  |       N/A\n",
            "loss            |     0.077  |     0.082\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.375329\n",
            "Estimated training time remaining: 0:00:25\n",
            "Epoch 37/99\n",
            "Peak CPU memory usage MB: 2619.164\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0700 ||: 100%|██████████| 18/18 [00:00<00:00, 64.90it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0802 ||: 100%|██████████| 2/2 [00:00<00:00, 165.74it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.164  |       N/A\n",
            "loss            |     0.070  |     0.080\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.379840\n",
            "Estimated training time remaining: 0:00:25\n",
            "Epoch 38/99\n",
            "Peak CPU memory usage MB: 2619.18\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0661 ||: 100%|██████████| 18/18 [00:00<00:00, 64.58it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0739 ||: 100%|██████████| 2/2 [00:00<00:00, 156.97it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.180  |       N/A\n",
            "loss            |     0.066  |     0.074\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.388196\n",
            "Estimated training time remaining: 0:00:24\n",
            "Epoch 39/99\n",
            "Peak CPU memory usage MB: 2619.18\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0623 ||: 100%|██████████| 18/18 [00:00<00:00, 66.59it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0680 ||: 100%|██████████| 2/2 [00:00<00:00, 148.46it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.180  |       N/A\n",
            "loss            |     0.062  |     0.068\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.380386\n",
            "Estimated training time remaining: 0:00:24\n",
            "Epoch 40/99\n",
            "Peak CPU memory usage MB: 2619.196\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0571 ||: 100%|██████████| 18/18 [00:00<00:00, 65.01it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0601 ||: 100%|██████████| 2/2 [00:00<00:00, 131.14it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.196  |       N/A\n",
            "loss            |     0.057  |     0.060\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.394691\n",
            "Estimated training time remaining: 0:00:23\n",
            "Epoch 41/99\n",
            "Peak CPU memory usage MB: 2619.196\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0557 ||: 100%|██████████| 18/18 [00:00<00:00, 66.07it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0644 ||: 100%|██████████| 2/2 [00:00<00:00, 139.85it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.196  |       N/A\n",
            "loss            |     0.056  |     0.064\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.381007\n",
            "Estimated training time remaining: 0:00:23\n",
            "Epoch 42/99\n",
            "Peak CPU memory usage MB: 2619.204\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0507 ||: 100%|██████████| 18/18 [00:00<00:00, 65.08it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0566 ||: 100%|██████████| 2/2 [00:00<00:00, 114.28it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.204  |       N/A\n",
            "loss            |     0.051  |     0.057\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.396281\n",
            "Estimated training time remaining: 0:00:22\n",
            "Epoch 43/99\n",
            "Peak CPU memory usage MB: 2619.204\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0477 ||: 100%|██████████| 18/18 [00:00<00:00, 64.53it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0548 ||: 100%|██████████| 2/2 [00:00<00:00, 136.79it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.204  |       N/A\n",
            "loss            |     0.048  |     0.055\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.390478\n",
            "Estimated training time remaining: 0:00:22\n",
            "Epoch 44/99\n",
            "Peak CPU memory usage MB: 2619.204\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0457 ||: 100%|██████████| 18/18 [00:00<00:00, 67.20it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0539 ||: 100%|██████████| 2/2 [00:00<00:00, 155.97it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.204  |       N/A\n",
            "loss            |     0.046  |     0.054\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.378213\n",
            "Estimated training time remaining: 0:00:22\n",
            "Epoch 45/99\n",
            "Peak CPU memory usage MB: 2619.204\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0424 ||: 100%|██████████| 18/18 [00:00<00:00, 66.00it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0485 ||: 100%|██████████| 2/2 [00:00<00:00, 155.98it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.204  |       N/A\n",
            "loss            |     0.042  |     0.048\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.380945\n",
            "Estimated training time remaining: 0:00:21\n",
            "Epoch 46/99\n",
            "Peak CPU memory usage MB: 2619.204\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0403 ||: 100%|██████████| 18/18 [00:00<00:00, 64.26it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0477 ||: 100%|██████████| 2/2 [00:00<00:00, 141.18it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.204  |       N/A\n",
            "loss            |     0.040  |     0.048\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.388143\n",
            "Estimated training time remaining: 0:00:21\n",
            "Epoch 47/99\n",
            "Peak CPU memory usage MB: 2619.204\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0385 ||: 100%|██████████| 18/18 [00:00<00:00, 64.77it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0442 ||: 100%|██████████| 2/2 [00:00<00:00, 210.01it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.204  |       N/A\n",
            "loss            |     0.039  |     0.044\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.392027\n",
            "Estimated training time remaining: 0:00:20\n",
            "Epoch 48/99\n",
            "Peak CPU memory usage MB: 2619.204\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0367 ||: 100%|██████████| 18/18 [00:00<00:00, 64.36it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0475 ||: 100%|██████████| 2/2 [00:00<00:00, 154.73it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.204  |       N/A\n",
            "loss            |     0.037  |     0.047\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.386893\n",
            "Estimated training time remaining: 0:00:20\n",
            "Epoch 49/99\n",
            "Peak CPU memory usage MB: 2619.204\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0348 ||: 100%|██████████| 18/18 [00:00<00:00, 65.01it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0439 ||: 100%|██████████| 2/2 [00:00<00:00, 140.65it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.204  |       N/A\n",
            "loss            |     0.035  |     0.044\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.389187\n",
            "Estimated training time remaining: 0:00:20\n",
            "Epoch 50/99\n",
            "Peak CPU memory usage MB: 2619.228\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0335 ||: 100%|██████████| 18/18 [00:00<00:00, 64.69it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0411 ||: 100%|██████████| 2/2 [00:00<00:00, 114.20it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.228  |       N/A\n",
            "loss            |     0.033  |     0.041\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.399692\n",
            "Estimated training time remaining: 0:00:19\n",
            "Epoch 51/99\n",
            "Peak CPU memory usage MB: 2619.228\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0312 ||: 100%|██████████| 18/18 [00:00<00:00, 66.91it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0404 ||: 100%|██████████| 2/2 [00:00<00:00, 144.14it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.228  |       N/A\n",
            "loss            |     0.031  |     0.040\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.381316\n",
            "Estimated training time remaining: 0:00:19\n",
            "Epoch 52/99\n",
            "Peak CPU memory usage MB: 2619.228\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0289 ||: 100%|██████████| 18/18 [00:00<00:00, 66.47it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0380 ||: 100%|██████████| 2/2 [00:00<00:00, 146.25it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.228  |       N/A\n",
            "loss            |     0.029  |     0.038\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.378509\n",
            "Estimated training time remaining: 0:00:18\n",
            "Epoch 53/99\n",
            "Peak CPU memory usage MB: 2619.228\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0278 ||: 100%|██████████| 18/18 [00:00<00:00, 65.10it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0380 ||: 100%|██████████| 2/2 [00:00<00:00, 145.78it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.228  |       N/A\n",
            "loss            |     0.028  |     0.038\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.395404\n",
            "Estimated training time remaining: 0:00:18\n",
            "Epoch 54/99\n",
            "Peak CPU memory usage MB: 2619.26\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0263 ||: 100%|██████████| 18/18 [00:00<00:00, 66.22it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0374 ||: 100%|██████████| 2/2 [00:00<00:00, 146.53it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.260  |       N/A\n",
            "loss            |     0.026  |     0.037\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.392183\n",
            "Estimated training time remaining: 0:00:17\n",
            "Epoch 55/99\n",
            "Peak CPU memory usage MB: 2619.308\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 0.9982, auc: 0.9972, loss: 0.0273 ||: 100%|██████████| 18/18 [00:00<00:00, 65.82it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0392 ||: 100%|██████████| 2/2 [00:00<00:00, 152.96it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.308  |       N/A\n",
            "loss            |     0.027  |     0.039\n",
            "auc             |     0.997  |     1.000\n",
            "accuracy        |     0.998  |     1.000\n",
            "Epoch duration: 0:00:00.378981\n",
            "Estimated training time remaining: 0:00:17\n",
            "Epoch 56/99\n",
            "Peak CPU memory usage MB: 2619.356\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0248 ||: 100%|██████████| 18/18 [00:00<00:00, 65.45it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0363 ||: 100%|██████████| 2/2 [00:00<00:00, 148.45it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.356  |       N/A\n",
            "loss            |     0.025  |     0.036\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.380099\n",
            "Estimated training time remaining: 0:00:17\n",
            "Epoch 57/99\n",
            "Peak CPU memory usage MB: 2619.388\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0235 ||: 100%|██████████| 18/18 [00:00<00:00, 68.03it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0360 ||: 100%|██████████| 2/2 [00:00<00:00, 166.81it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.388  |       N/A\n",
            "loss            |     0.023  |     0.036\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.397094\n",
            "Estimated training time remaining: 0:00:16\n",
            "Epoch 58/99\n",
            "Peak CPU memory usage MB: 2619.436\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0218 ||: 100%|██████████| 18/18 [00:00<00:00, 64.56it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0335 ||: 100%|██████████| 2/2 [00:00<00:00, 137.44it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.436  |       N/A\n",
            "loss            |     0.022  |     0.033\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.376073\n",
            "Estimated training time remaining: 0:00:16\n",
            "Epoch 59/99\n",
            "Peak CPU memory usage MB: 2619.484\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0221 ||: 100%|██████████| 18/18 [00:00<00:00, 67.23it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0331 ||: 100%|██████████| 2/2 [00:00<00:00, 155.82it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.484  |       N/A\n",
            "loss            |     0.022  |     0.033\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.373096\n",
            "Estimated training time remaining: 0:00:15\n",
            "Epoch 60/99\n",
            "Peak CPU memory usage MB: 2619.532\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0202 ||: 100%|██████████| 18/18 [00:00<00:00, 66.82it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0324 ||: 100%|██████████| 2/2 [00:00<00:00, 123.36it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.532  |       N/A\n",
            "loss            |     0.020  |     0.032\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.379561\n",
            "Estimated training time remaining: 0:00:15\n",
            "Epoch 61/99\n",
            "Peak CPU memory usage MB: 2619.58\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0204 ||: 100%|██████████| 18/18 [00:00<00:00, 64.09it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0323 ||: 100%|██████████| 2/2 [00:00<00:00, 160.63it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.580  |       N/A\n",
            "loss            |     0.020  |     0.032\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.386615\n",
            "Estimated training time remaining: 0:00:15\n",
            "Epoch 62/99\n",
            "Peak CPU memory usage MB: 2619.628\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0176 ||: 100%|██████████| 18/18 [00:00<00:00, 66.96it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0323 ||: 100%|██████████| 2/2 [00:00<00:00, 153.76it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.628  |       N/A\n",
            "loss            |     0.018  |     0.032\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.384049\n",
            "Estimated training time remaining: 0:00:14\n",
            "Epoch 63/99\n",
            "Peak CPU memory usage MB: 2619.676\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0179 ||: 100%|██████████| 18/18 [00:00<00:00, 65.22it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0312 ||: 100%|██████████| 2/2 [00:00<00:00, 193.40it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.676  |       N/A\n",
            "loss            |     0.018  |     0.031\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.392960\n",
            "Estimated training time remaining: 0:00:14\n",
            "Epoch 64/99\n",
            "Peak CPU memory usage MB: 2619.708\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0168 ||: 100%|██████████| 18/18 [00:00<00:00, 65.57it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0301 ||: 100%|██████████| 2/2 [00:00<00:00, 162.83it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.708  |       N/A\n",
            "loss            |     0.017  |     0.030\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.400527\n",
            "Estimated training time remaining: 0:00:13\n",
            "Epoch 65/99\n",
            "Peak CPU memory usage MB: 2619.756\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0166 ||: 100%|██████████| 18/18 [00:00<00:00, 65.90it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0296 ||: 100%|██████████| 2/2 [00:00<00:00, 156.85it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.756  |       N/A\n",
            "loss            |     0.017  |     0.030\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.376508\n",
            "Estimated training time remaining: 0:00:13\n",
            "Epoch 66/99\n",
            "Peak CPU memory usage MB: 2619.804\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0168 ||: 100%|██████████| 18/18 [00:00<00:00, 63.47it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0305 ||: 100%|██████████| 2/2 [00:00<00:00, 205.73it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.804  |       N/A\n",
            "loss            |     0.017  |     0.031\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.394867\n",
            "Estimated training time remaining: 0:00:13\n",
            "Epoch 67/99\n",
            "Peak CPU memory usage MB: 2619.852\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0157 ||: 100%|██████████| 18/18 [00:00<00:00, 65.92it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0306 ||: 100%|██████████| 2/2 [00:00<00:00, 170.43it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.852  |       N/A\n",
            "loss            |     0.016  |     0.031\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.376443\n",
            "Estimated training time remaining: 0:00:12\n",
            "Epoch 68/99\n",
            "Peak CPU memory usage MB: 2619.9\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0138 ||: 100%|██████████| 18/18 [00:00<00:00, 67.85it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0291 ||: 100%|██████████| 2/2 [00:00<00:00, 136.38it/s]\n",
            "                    Training |  Validation\n",
            "gpu_0_memory_MB |   775.000  |       N/A\n",
            "cpu_memory_MB   |  2619.900  |       N/A\n",
            "loss            |     0.014  |     0.029\n",
            "auc             |     1.000  |     1.000\n",
            "accuracy        |     1.000  |     1.000\n",
            "Epoch duration: 0:00:00.372340\n",
            "Estimated training time remaining: 0:00:12\n",
            "Epoch 69/99\n",
            "Peak CPU memory usage MB: 2619.948\n",
            "GPU 0 memory usage MB: 775\n",
            "Training\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0146 ||: 100%|██████████| 18/18 [00:00<00:00, 66.64it/s]\n",
            "Validating\n",
            "accuracy: 1.0000, auc: 1.0000, loss: 0.0284 ||: 100%|██████████| 2/2 [00:00<00:00, 152.91it/s]\n",
            "Ran out of patience.  Stopping training.\n",
            "cannot load best weights without `serialization_dir`, so you're just getting the last weights\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 19,\n",
              " 'best_validation_accuracy': 1.0,\n",
              " 'best_validation_auc': 1.0,\n",
              " 'best_validation_loss': 0.31568722426891327,\n",
              " 'epoch': 68,\n",
              " 'peak_cpu_memory_MB': 2619.948,\n",
              " 'peak_gpu_0_memory_MB': 775,\n",
              " 'training_accuracy': 1.0,\n",
              " 'training_auc': 1.0,\n",
              " 'training_cpu_memory_MB': 2619.9,\n",
              " 'training_duration': '0:00:27.402971',\n",
              " 'training_epochs': 68,\n",
              " 'training_gpu_0_memory_MB': 775,\n",
              " 'training_loss': 0.013782099924153753,\n",
              " 'training_start_epoch': 0,\n",
              " 'validation_accuracy': 1.0,\n",
              " 'validation_auc': 1.0,\n",
              " 'validation_loss': 0.029057467356324196}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqDwQXM4K-Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Save\n",
        "with open(\"./model.th\", 'wb') as f:\n",
        "    torch.save(model.state_dict(), f)\n",
        "vocab.save_to_files(\"./vocabulary\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX1_Uct67zfU",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBKqF-0ALLsP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3769909c-754d-4707-a89c-28ba7983a015"
      },
      "source": [
        "# Model Reload\n",
        "vocab2 = Vocabulary.from_files(\"./vocabulary\")\n",
        "model2 = Lv1Net(vocab = vocab,\n",
        "               text_field_embedder = embedder,\n",
        "               seq2vec_encoder = encoder,\n",
        "               num_labels = 2,\n",
        "               dropout_prob = dropout_prob\n",
        "               )\n",
        "\n",
        "with open(\"./model.th\", 'rb') as f:\n",
        "    model2.load_state_dict(torch.load(f))\n",
        "if cuda_device > -1:\n",
        "    model2.cuda(cuda_device)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading token dictionary from ./vocabulary.\n",
            "Initializing parameters\n",
            "Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "   _classification_layer.bias\n",
            "   _classification_layer.weight\n",
            "   _seq2vec_encoder.conv_layer_0.bias\n",
            "   _seq2vec_encoder.conv_layer_0.weight\n",
            "   _seq2vec_encoder.conv_layer_1.bias\n",
            "   _seq2vec_encoder.conv_layer_1.weight\n",
            "   _seq2vec_encoder.conv_layer_2.bias\n",
            "   _seq2vec_encoder.conv_layer_2.weight\n",
            "   _seq2vec_encoder.conv_layer_3.bias\n",
            "   _seq2vec_encoder.conv_layer_3.weight\n",
            "   _text_field_embedder.token_embedder_tokens.weight\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmmvtKLVKzQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.predictors.predictor import Predictor\n",
        "\n",
        "predictor = Predictor(model2, reader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ncxwf2ONOl9",
        "colab_type": "code",
        "outputId": "b54bdeba-270d-485a-eb09-a2c74360f08c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "level1_pred = []\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "TEST_FILE = 'level1_test.tsv'\n",
        "#TEST_FILE = 'level2_test.tsv'\n",
        "TEST_PATH = os.path.join(DATA_DIR, TEST_FILE)\n",
        "test_dataset = reader.read(TEST_PATH)\n",
        "\n",
        "for instance in tqdm(test_dataset):\n",
        "    ans = predictor.predict_instance(instance)\n",
        "    level1_pred.append(ans['label'])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200it [00:00, 6396.93it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 357.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mKQ-ARc3S9L",
        "colab_type": "code",
        "outputId": "42e9fc2d-6d78-499b-91f3-501ff923b515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "level1_pred_df = pd.DataFrame(level1_pred)\n",
        "level1_pred_df.T"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  0   1   2   3   4   5   6   7   8    ... 191 192 193 194 195 196 197 198 199\n",
              "0   1   1   1   1   1   0   1   0   1  ...   1   1   1   1   1   1   0   0   0\n",
              "\n",
              "[1 rows x 200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W-V1q24lBgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "level1_pred_df.T.to_csv('level1_pred.csv', index = False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zo0fXN6jAch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('level1_pred.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u12jZX4XitXC",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation (Only on Google Colab)\n",
        "\n",
        "If you have labeled test data distributed by administrators, you can calculate performance score.  \n",
        "Please put them into your google drive and mount it by commands below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObaxULIKivwh",
        "colab_type": "code",
        "outputId": "86611d6f-66ee-4d83-bfa4-d50ecbfc5dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf92Q1-Bi23B",
        "colab_type": "code",
        "outputId": "0917a3ec-c885-40fd-c7b4-5bbe65307592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LABEL_PATH = \"/content/drive/My Drive/SECCON/level2_test.tsv\" # Path to labeled data\n",
        "label_dataset = reader.read(LABEL_PATH)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200it [00:00, 488.86it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI18aYjYLkVs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d39cd5da-95c9-4425-a8da-84b2b719a450"
      },
      "source": [
        "# Model Reload\n",
        "vocab2 = Vocabulary.from_files(\"./vocabulary\")\n",
        "model2 = Lv1Net(vocab = vocab,\n",
        "               text_field_embedder = embedder,\n",
        "               seq2vec_encoder = encoder,\n",
        "               num_labels = 2,\n",
        "               dropout_prob = dropout_prob\n",
        "               )\n",
        "\n",
        "with open(\"./model.th\", 'rb') as f:\n",
        "    model2.load_state_dict(torch.load(f))\n",
        "if cuda_device > -1:\n",
        "    model2.cuda(cuda_device)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading token dictionary from ./vocabulary.\n",
            "Initializing parameters\n",
            "Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "   _classification_layer.bias\n",
            "   _classification_layer.weight\n",
            "   _seq2vec_encoder.conv_layer_0.bias\n",
            "   _seq2vec_encoder.conv_layer_0.weight\n",
            "   _seq2vec_encoder.conv_layer_1.bias\n",
            "   _seq2vec_encoder.conv_layer_1.weight\n",
            "   _seq2vec_encoder.conv_layer_2.bias\n",
            "   _seq2vec_encoder.conv_layer_2.weight\n",
            "   _seq2vec_encoder.conv_layer_3.bias\n",
            "   _seq2vec_encoder.conv_layer_3.weight\n",
            "   _text_field_embedder.token_embedder_tokens.weight\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EDDg5bCjCOs",
        "colab_type": "code",
        "outputId": "b1d3ce4c-8749-420b-c9b3-b6f2ea1c9911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from allennlp.training.util import evaluate\n",
        "metrics = evaluate(model, label_dataset, iterator, cuda_device, batch_weight_key=\"\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iterating over dataset\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n",
            "accuracy: 1.00, auc: 1.00, loss: 0.01 ||: 100%|██████████| 7/7 [00:00<00:00, 77.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMGpZn_EHhyA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6df98499-f9ba-4b57-80b0-59b9fbdca0a4"
      },
      "source": [
        "metrics"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 1.0, 'auc': 1.0, 'loss': 0.012788805844528335}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}